{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import math\n",
    "import statistics\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Data_From_JSON(json_dict):\n",
    "    time_stamps = json_dict[\"Timestamp\"]\n",
    "    all_tools = json_dict[\"Recordings\"]\n",
    "    ## find drill\n",
    "    for tool_rec in all_tools:\n",
    "        if tool_rec[\"ToolName\"] == \"Unium_Drill\":\n",
    "            drill_info = tool_rec[\"Info\"]\n",
    "            drill_translation = tool_rec[\"Translation\"]\n",
    "            drill_rotation = tool_rec[\"Rotation\"]\n",
    "    # basic info loading\n",
    "    drill_df = pd.DataFrame()\n",
    "    drill_df[\"ActivityLabel\"] = drill_info[\"ActivityLabel\"]\n",
    "    drill_df[\"Translation_X\"] = drill_translation[\"X\"]\n",
    "    drill_df[\"Translation_Y\"] = drill_translation[\"Y\"]\n",
    "    drill_df[\"Translation_Z\"] = drill_translation[\"Z\"]\n",
    "    drill_df[\"Rotation_X\"] = drill_rotation[\"X\"]\n",
    "    drill_df[\"Rotation_Y\"] = drill_rotation[\"Y\"]\n",
    "    drill_df[\"Rotation_Z\"] = drill_rotation[\"Z\"]\n",
    "    drill_df[\"Rotation_W\"] = drill_rotation[\"W\"]\n",
    "    drill_df[\"time_stamps\"] = time_stamps\n",
    "    return drill_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the trajectory, outlier removal, and create manual index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance helper\n",
    "def Distance(x1, y1, z1, x2, y2, z2):\n",
    "    d = 0.0\n",
    "    d = math.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
    "    return d\n",
    "\n",
    "# Change-of-location outlier removal\n",
    "def Outlier_Removal(cur_df):\n",
    "    # calculate distances btw points\n",
    "    distances = []\n",
    "    distances.append(0.0)\n",
    "    removal_indices = []\n",
    "    for i in range(cur_df.shape[0] - 1):\n",
    "        prev = cur_df.iloc[i]\n",
    "        cur = cur_df.iloc[i + 1]\n",
    "        distance = Distance(prev[\"Translation_X\"], prev[\"Translation_Y\"], prev[\"Translation_Z\"], cur[\"Translation_X\"], cur[\"Translation_Y\"], cur[\"Translation_Z\"])\n",
    "        distances.append(distance)\n",
    "    print(\"Before removal, there are: \" + str(len(distances)) + \" points.\")\n",
    "    mean = statistics.mean(distances)\n",
    "    std = statistics.stdev(distances)\n",
    "    threshold = mean + 3 * std\n",
    "    for i in range(len(distances)):\n",
    "        if distances[i] > threshold:\n",
    "            removal_indices.append(i)\n",
    "    print(\"Following indices are removed:\")\n",
    "    print (*removal_indices, sep=\",\")\n",
    "    removed_df = cur_df.drop(removal_indices)\n",
    "    return removed_df\n",
    "\n",
    "# Moving average filtering (compression, smoothing outliers, and filtering at same time)\n",
    "def Moving_Average_Filtering(cur_df, factor=3):\n",
    "    window_size = factor**2\n",
    "    cur_df['average_translation_X'] = cur_df[\"Translation_X\"].rolling(window_size).mean()\n",
    "    cur_df['average_translation_Y'] = cur_df[\"Translation_Y\"].rolling(window_size).mean()\n",
    "    cur_df['average_translation_Z'] = cur_df[\"Translation_Z\"].rolling(window_size).mean()\n",
    "\n",
    "    cur_df['average_rotation_X'] = cur_df[\"Rotation_X\"].rolling(window_size).mean()\n",
    "    cur_df['average_rotation_Y'] = cur_df[\"Rotation_Y\"].rolling(window_size).mean()\n",
    "    cur_df['average_rotation_Z'] = cur_df[\"Rotation_Z\"].rolling(window_size).mean()\n",
    "    cur_df['average_rotation_W'] = cur_df[\"Rotation_W\"].rolling(window_size).mean()\n",
    "\n",
    "    cur_df.dropna(inplace = True)\n",
    "\n",
    "    cur_df = cur_df.iloc[::factor, :]\n",
    "    return cur_df\n",
    "\n",
    "def Create_Manual_Index(time_stamps):\n",
    "    manual_index = []\n",
    "    for i in range(len(time_stamps)):\n",
    "        manual_index.append(i)\n",
    "    return manual_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix(translation_x, translation_y, translation_z, rotation_x, rotation_y, rotation_z, rotation_w):\n",
    "    T = np.zeros((4, 4), dtype=np.float32)\n",
    "    T[:-1, 3] = [translation_x, translation_y, translation_z]\n",
    "    T[0:3, 0:3] = R.from_quat([rotation_x, rotation_y, rotation_z, rotation_w]).as_matrix()\n",
    "    T[3, 3] = 1\n",
    "    return T\n",
    "\n",
    "def get_inverse(T):\n",
    "    inv = np.zeros(T.shape, dtype=np.float32)\n",
    "    inv[0:3, 0:3] = T[0:3, 0:3].T\n",
    "    trans = -T[0:3, 0:3].T @ T[:-1, 3]\n",
    "    inv[:-1, 3] = trans\n",
    "    inv[3, 3] = 1\n",
    "    return inv\n",
    "\n",
    "def get_intrinsic_distance(translation_x, translation_y, translation_z, rotation_x, rotation_y, rotation_z, rotation_w):\n",
    "    intrinsics = []\n",
    "    for i in range(len(translation_x) - 1):\n",
    "        T_cur = get_matrix(translation_x[i], translation_y[i], translation_z[i], rotation_x[i], rotation_y[i], rotation_z[i],\n",
    "                          rotation_w[i])\n",
    "        T_next = get_matrix(translation_x[i + 1], translation_y[i + 1], translation_z[i + 1], \n",
    "                            rotation_x[i + 1], rotation_y[i + 1], rotation_z[i + 1], rotation_w[i+1])\n",
    "        T_delta = get_inverse(T_cur) @ T_next\n",
    "        quats = R.from_matrix(T_delta[:3, :3]).as_quat()\n",
    "        intrinsics.append(np.concatenate((T_delta[:-1, 3], quats)))\n",
    "    return intrinsics\n",
    "\n",
    "def Construct_Intrinsic_Features(drill_df):\n",
    "    intrinsics = get_intrinsic_distance(drill_df['Translation_X'].to_list(), drill_df['Translation_Y'].to_list(), \n",
    "                                    drill_df['Translation_Z'].to_list(), drill_df['Rotation_X'].to_list(), \n",
    "                                    drill_df['Rotation_Y'].to_list(), drill_df['Rotation_Z'].to_list(), drill_df['Rotation_W'].to_list())\n",
    "    numpy_intrinsics = np.array(intrinsics)\n",
    "    intrinsic_translation_x = numpy_intrinsics[:,0]\n",
    "    intrinsic_translation_x = np.insert(intrinsic_translation_x,0,intrinsic_translation_x[0])\n",
    "    intrinsic_translation_y = numpy_intrinsics[:,1]\n",
    "    intrinsic_translation_y = np.insert(intrinsic_translation_y,0,intrinsic_translation_y[0])\n",
    "    intrinsic_translation_z = numpy_intrinsics[:,2]\n",
    "    intrinsic_translation_z = np.insert(intrinsic_translation_z,0,intrinsic_translation_z[0])\n",
    "    intrinsic_rotation_x = numpy_intrinsics[:,3]\n",
    "    intrinsic_rotation_x = np.insert(intrinsic_rotation_x,0,intrinsic_rotation_x[0])\n",
    "    intrinsic_rotation_y = numpy_intrinsics[:,4]\n",
    "    intrinsic_rotation_y = np.insert(intrinsic_rotation_y,0,intrinsic_rotation_y[0])\n",
    "    intrinsic_rotation_z = numpy_intrinsics[:,5]\n",
    "    intrinsic_rotation_z = np.insert(intrinsic_rotation_z,0,intrinsic_rotation_z[0])\n",
    "    intrinsic_rotation_w = numpy_intrinsics[:,6]\n",
    "    intrinsic_rotation_w = np.insert(intrinsic_rotation_w,0,intrinsic_rotation_w[0])\n",
    "\n",
    "    # scale the intrinsic feature for future analysis\n",
    "\n",
    "    drill_df[\"intrinsic_translation_x\"] = intrinsic_translation_x * 1000\n",
    "    drill_df[\"intrinsic_translation_y\"] = intrinsic_translation_y * 1000\n",
    "    drill_df[\"intrinsic_translation_z\"] = intrinsic_translation_z * 1000\n",
    "\n",
    "    drill_df[\"intrinsic_rotation_x\"] = intrinsic_rotation_x\n",
    "    drill_df[\"intrinsic_rotation_y\"] = intrinsic_rotation_y\n",
    "    drill_df[\"intrinsic_rotation_z\"] = intrinsic_rotation_z\n",
    "    drill_df[\"intrinsic_rotation_w\"] = intrinsic_rotation_w"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Event protocal loading and construct key-dictionary pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_Drillin(drill_in_df):\n",
    "    drill_in_df = drill_in_df[drill_in_df[\"ActivityLabel\"] == 0]\n",
    "    return drill_in_df\n",
    "\n",
    "# returns indices of the end of segments\n",
    "def Find_Segments(df):\n",
    "    indices = []\n",
    "    manual_index = df[\"manual_index\"].to_list()\n",
    "    for i in range(len(manual_index) - 1):\n",
    "        if not (int(manual_index[i]) + 1 == int(manual_index[i + 1])):\n",
    "            indices.append(i)\n",
    "            if len(indices) == 10:\n",
    "                break\n",
    "    print(\"indices found for current file: \"+ str(len(indices)))\n",
    "    return indices\n",
    "\n",
    "# get three penetration values from the txt file\n",
    "def Get_Penetration(file_name):\n",
    "    print(\"Loading event file: \" + file_name)\n",
    "    penetrations = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        text = file.read().replace('\\n', '')\n",
    "        all_indices = [m.end() for m in re.finditer('drillSoftTissuePenetration', text)]\n",
    "        first_drill_index = all_indices[0] + 2\n",
    "        second_drill_index = all_indices[1] + 2\n",
    "        last_drill_index = all_indices[len(all_indices) - 1] + 2\n",
    "\n",
    "        ## convert to millimeters\n",
    "        first_penetration = round(float(text[first_drill_index : first_drill_index + 8]) * 1000, 2)\n",
    "        second_penetration = round(float(text[second_drill_index : second_drill_index + 8]) * 1000, 2)\n",
    "        last_penetration = round(float(text[last_drill_index : last_drill_index + 8]) * 1000, 2)\n",
    "\n",
    "        penetrations.extend([first_penetration, second_penetration, last_penetration])\n",
    "        return penetrations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data loading and extracted feature df construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not enabling noise filter here, as MA smoothing will do the job and there's no extreme measurement errors\n",
    "def Load_All(data_path, storeage_df):\n",
    "    \"\"\"Load all data\"\"\"\n",
    "    ### data_path is the path of data from CURRENT directory!\n",
    "    os_path = os.getcwd()\n",
    "    json_files = glob.glob(os.path.join(os_path, data_path,\"*.json\"))\n",
    "    for file in json_files:\n",
    "        print(\"Loading file: \" + file)\n",
    "        with open(file, \"rb\") as json_file:\n",
    "            cur_json_dict = json.load(json_file)\n",
    "            cur_drill_df = Get_Data_From_JSON(cur_json_dict)\n",
    "            # filter the trajectory here\n",
    "            cur_manual_index = Create_Manual_Index(cur_drill_df[\"time_stamps\"])\n",
    "            cur_drill_df[\"manual_index\"] = cur_manual_index\n",
    "            Construct_Intrinsic_Features(cur_drill_df)\n",
    "            cur_drill_df = Extract_Drillin(cur_drill_df)\n",
    "            cur_end_indices = Find_Segments(cur_drill_df)\n",
    "            # construct segments\n",
    "            cur_feature_list = []\n",
    "            first_drill_in_df = cur_drill_df.iloc[:cur_end_indices[0] + 1, :]\n",
    "            #first_drill_in_df = Outlier_Removal(first_drill_in_df)\n",
    "            first_drill_in_df = Moving_Average_Filtering(first_drill_in_df, 3)\n",
    "\n",
    "            second_drill_in_df = cur_drill_df.iloc[cur_end_indices[0] + 1: cur_end_indices[1] + 1, :]\n",
    "            #second_drill_in_df = Outlier_Removal(second_drill_in_df)\n",
    "            second_drill_in_df = Moving_Average_Filtering(second_drill_in_df, 3)\n",
    "\n",
    "            # not using filtering for the third drill here, as the third drill is already short in most cases.\n",
    "            thrid_drill_in_df = cur_drill_df.iloc[cur_end_indices[2] + 1 :, :]\n",
    "            #thrid_drill_in_df = Outlier_Removal(thrid_drill_in_df)\n",
    "            thrid_drill_in_df = Moving_Average_Filtering(thrid_drill_in_df, 2)\n",
    "\n",
    "            cur_feature_list.extend([first_drill_in_df, second_drill_in_df, thrid_drill_in_df])\n",
    "            cur_penetrations_in_mm = Get_Penetration(file[:len(file) - 17] + \"_EventProtocol.txt\")\n",
    "            # construct key-value pairs for penetration and dictionary\n",
    "            cur_df = pd.DataFrame(zip(cur_penetrations_in_mm, cur_feature_list), columns=[\"Penetration\", \"Feature_df\"])\n",
    "            storeage_df = pd.concat([storeage_df,cur_df], axis=0)\n",
    "    return storeage_df "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all and return extracted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_df(training_or_inference = \"traning\"):\n",
    "    path_dataset = training_or_inference + \"_data\"\n",
    "    extracted_features_df = pd.DataFrame()\n",
    "    extracted_features_df = Load_All(path_dataset, extracted_features_df)\n",
    "    return extracted_features_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction (based on surgical features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Velocity and Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Speed_Filter(intrinsic_list, level = 0.001):\n",
    "    return [x for x in intrinsic_list if abs(x) > level]\n",
    "\n",
    "def Calculate_Mean_Speed(intrinsic_list):\n",
    "    filtered_list = Speed_Filter(intrinsic_list)\n",
    "    return statistics.mean(filtered_list)\n",
    "\n",
    "def Calculate_ABS_Mean_Speed(intrinsic_list):\n",
    "    filtered_list = Speed_Filter(intrinsic_list)\n",
    "    abs_filtered_list = []\n",
    "    for speed in filtered_list:\n",
    "        abs_filtered_list.append(abs(speed))\n",
    "    return statistics.mean(abs_filtered_list)\n",
    "\n",
    "def Calculate_Standard_Deviation_Speed(intrinsic_list):\n",
    "    filtered_list = Speed_Filter(intrinsic_list)\n",
    "    return statistics.stdev(filtered_list)\n",
    "\n",
    "def Max_Forward(intrinsic_list):\n",
    "    filtered_list = Speed_Filter(intrinsic_list)\n",
    "    forward_list = [x for x in filtered_list if x > 0]\n",
    "    return max(forward_list)\n",
    "\n",
    "def Max_Backword(intrinsic_list):\n",
    "    filtered_list = Speed_Filter(intrinsic_list)\n",
    "    backward_list = [x for x in filtered_list if x < 0]\n",
    "    abs_backward = []\n",
    "    for speed in backward_list:\n",
    "        abs_backward.append(abs(speed))\n",
    "    return max(abs_backward)\n",
    "\n",
    "def Forward_Mean_Speed(intrinsic_list):\n",
    "    filtered_list = Speed_Filter(intrinsic_list)\n",
    "    forward_list = [x for x in filtered_list if x > 0]\n",
    "    return statistics.mean(forward_list)\n",
    "\n",
    "def Backward_Mean_Speed(intrinsic_list):\n",
    "    filtered_list = Speed_Filter(intrinsic_list)\n",
    "    backward_list = [x for x in filtered_list if x < 0]\n",
    "    abs_backward = []\n",
    "    for speed in backward_list:\n",
    "        abs_backward.append(abs(speed))\n",
    "    return statistics.mean(abs_backward)\n",
    "\n",
    "def Calculate_Acceleration(intrinsic_list):\n",
    "    filtered_intrinsic = Speed_Filter(intrinsic_list)\n",
    "    acceleration_list = []\n",
    "    for i in range(len(filtered_intrinsic) - 1):\n",
    "        acceleration_list.append(filtered_intrinsic[i + 1] - filtered_intrinsic[i])\n",
    "    return acceleration_list\n",
    "\n",
    "def Mean_Acceleration(intrinsic_list):\n",
    "    acceleration_list = Calculate_Acceleration(intrinsic_list)\n",
    "    return statistics.mean([x for x in acceleration_list if x > 0])\n",
    "\n",
    "def Mean_Deacceleration(intrinsic_list):\n",
    "    acceleration_list = Calculate_Acceleration(intrinsic_list)\n",
    "    deacceleration = [x for x in acceleration_list if x < 0]\n",
    "    return abs(statistics.mean(deacceleration))\n",
    "\n",
    "def Max_Acceleration(intrinsic_list):\n",
    "    acceleration_list = Calculate_Acceleration(intrinsic_list)\n",
    "    return max([x for x in acceleration_list if x > 0])\n",
    "\n",
    "def Max_Deacceleration(intrinsic_list):\n",
    "    acceleration_list = Calculate_Acceleration(intrinsic_list)\n",
    "    deacceleration = [x for x in acceleration_list if x < 0]\n",
    "    return abs(min(deacceleration))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hand movements and drill time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ger_Drill_Time(intrinsic_list):\n",
    "    return len(intrinsic_list)\n",
    "\n",
    "# Different threshold of movements normalized with time\n",
    "def Get_Num_Movements_Portion(intrinsic_list, threshold = 0.1):\n",
    "    accelerations = Calculate_Acceleration(intrinsic_list)\n",
    "    acceleration_list = [x for x in accelerations if x > 0]\n",
    "    deacceleration_list = [x for x in accelerations if x < 0]\n",
    "    count = 0\n",
    "    for acc in acceleration_list:\n",
    "        if acc > threshold:\n",
    "            count += 1\n",
    "    for deacc in deacceleration_list:\n",
    "        if abs(deacc) > threshold:\n",
    "            count += 1\n",
    "    return count/len(accelerations)\n",
    "\n",
    "def Get_Speed_Portion(intrinsic_list, threshold = 0.1):\n",
    "    count = 0\n",
    "    filtered_list = Speed_Filter(intrinsic_list)\n",
    "    for speed in filtered_list:\n",
    "        if abs(speed) > threshold:\n",
    "            count += 1\n",
    "    return count/len(filtered_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Construct_Features(df_input):\n",
    "    df = df_input.copy()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    for index, row in df.iterrows():\n",
    "        intrinsic_x_list = row[\"Feature_df\"][\"intrinsic_translation_x\"].to_list()\n",
    "        intrinsic_y_list = row[\"Feature_df\"][\"intrinsic_translation_y\"].to_list()\n",
    "        intrinsic_z_list = row[\"Feature_df\"][\"intrinsic_translation_z\"].to_list()\n",
    "        #extracted_features_df.loc[index,\"Mean_Speed_in_mm_per_timeframe\"] = Calculate_Mean_Speed(intrinsic_x_list)\n",
    "        #df.loc[index,\"Mean_ABS_Speed\"] = Calculate_ABS_Mean_Speed(intrinsic_x_list)\n",
    "        df.loc[index,\"Sdv_Speed_in_mm\"] = Calculate_Standard_Deviation_Speed(intrinsic_x_list)\n",
    "        #extracted_features_df.loc[index,\"Max_Forward_in_mm_per_timeframe\"] = Max_Forward(intrinsic_x_list)\n",
    "        #extracted_features_df.loc[index,\"Max_Backward_in_mm_per_timeframe\"] = Max_Backword(intrinsic_x_list)\n",
    "        df.loc[index,\"Mean_Forward_in_mm_per_timeframe\"] = Forward_Mean_Speed(intrinsic_x_list)\n",
    "        df.loc[index,\"Mean_Backward_in_mm\"] = Backward_Mean_Speed(intrinsic_x_list)\n",
    "        df.loc[index,\"Mean_Acceleration_in_mm\"] = Mean_Acceleration(intrinsic_x_list)\n",
    "        df.loc[index,\"Mean_Deacceleration_in_mm\"] = Mean_Deacceleration(intrinsic_x_list)\n",
    "        #extracted_features_df.loc[index,\"Max_Acceleration_in_mm\"] = Max_Acceleration(intrinsic_x_list)\n",
    "        #extracted_features_df.loc[index,\"Max_Deacceleration_in_mm\"] = Max_Deacceleration(intrinsic_x_list)\n",
    "        df.loc[index,\"Time_Used\"] = Ger_Drill_Time(intrinsic_x_list)\n",
    "        #df.loc[index,\"Proportion_Hand_Movement_Above_0.1\"] = Get_Num_Movements_Portion(intrinsic_x_list)\n",
    "        df.loc[index,\"Proportion_Hand_Movement_Above_0.05\"] = Get_Num_Movements_Portion(intrinsic_x_list, 0.05)\n",
    "        #df.loc[index,\"Proportion_Hand_Movement_Above_0.15\"] = Get_Num_Movements_Portion(intrinsic_x_list, 0.15)\n",
    "        #df.loc[index,\"Proportion_Hand_Movement_Above_0.3\"] = Get_Num_Movements_Portion(intrinsic_x_list, 0.3)\n",
    "        #extracted_features_df.loc[index,\"Proportion_Hand_Movement_Above_0.5\"] = Get_Num_Movements_Portion(intrinsic_x_list, 0.5)\n",
    "\n",
    "        df.loc[index,\"Proportion_Speed_Above_0.4\"] = Get_Speed_Portion(intrinsic_x_list, 0.4)\n",
    "        #df.loc[index,\"Proportion_Speed_Above_0.5\"] = Get_Speed_Portion(intrinsic_x_list, 0.5)\n",
    "        #df.loc[index,\"Proportion_Speed_Above_0.8\"] = Get_Speed_Portion(intrinsic_x_list, 0.8)\n",
    "\n",
    "        df.loc[index,\"Sdv_Y\"] = Calculate_Standard_Deviation_Speed(intrinsic_y_list)\n",
    "        df.loc[index,\"Sdv_Z\"] = Calculate_Standard_Deviation_Speed(intrinsic_z_list)\n",
    "        df.loc[index,\"Mean_ABS_Speed_Y\"] = Calculate_ABS_Mean_Speed(intrinsic_y_list)\n",
    "        df.loc[index,\"Mean_ABS_Speed_Z\"] = Calculate_ABS_Mean_Speed(intrinsic_z_list)\n",
    "        #extracted_features_df.loc[index,\"Mean_Speed_Y_in_mm_per_timeframe\"] = Calculate_Mean_Speed(intrinsic_y_list)\n",
    "        #df.loc[index,\"Mean_Speed_Z_in_mm_per_timeframe\"] = Calculate_Mean_Speed(intrinsic_z_list)\n",
    "        \n",
    "        #extracted_features_df.loc[index,\"Proportion_Hand_Movement_0.1_Y\"] = Get_Num_Movements_Portion(intrinsic_y_list)\n",
    "        df.loc[index,\"Proportion_Hand_Movement_0.05_Y\"] = Get_Num_Movements_Portion(intrinsic_y_list, 0.05)\n",
    "        #extracted_features_df.loc[index,\"Proportion_Hand_Movement_0.15_Y\"] = Get_Num_Movements_Portion(intrinsic_y_list, 0.15)\n",
    "        #extracted_features_df.loc[index,\"Proportion_Hand_Movement_0.3_Y\"] = Get_Num_Movements_Portion(intrinsic_y_list, 0.3)\n",
    "        df.loc[index,\"Proportion_Speed_Above_0.4_Y\"] = Get_Speed_Portion(intrinsic_y_list, 0.4)\n",
    "\n",
    "        #extracted_features_df.loc[index,\"Proportion_Hand_Movement_0.1_Z\"] = Get_Num_Movements_Portion(intrinsic_z_list)\n",
    "        df.loc[index,\"Proportion_Hand_Movement_0.05_Z\"] = Get_Num_Movements_Portion(intrinsic_z_list, 0.05)\n",
    "        #extracted_features_df.loc[index,\"Proportion_Hand_Movement_0.15_Z\"] = Get_Num_Movements_Portion(intrinsic_z_list, 0.15)\n",
    "        #extracted_features_df.loc[index,\"Proportion_Hand_Movement_0.3_Z\"] = Get_Num_Movements_Portion(intrinsic_z_list, 0.3)\n",
    "        df.loc[index,\"Proportion_Speed_Above_0.4_Z\"] = Get_Speed_Portion(intrinsic_z_list, 0.4)\n",
    "        if index % 3 != 2:\n",
    "            df.loc[index, \"Type_of_Drill\"] = int(0)\n",
    "        else:\n",
    "            df.loc[index, \"Type_of_Drill\"] = int(1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline_run(training_or_inference = \"training\", saving_directory = \"extracted_data\"):\n",
    "    key_val_df= construct_df(training_or_inference)\n",
    "    features_df = Construct_Features(key_val_df)\n",
    "    features_df = features_df.drop([\"Feature_df\"], axis=1)\n",
    "    X = features_df.iloc[:, 1:]\n",
    "    y = features_df.iloc[:, 0]\n",
    "    X_path = os.path.join(saving_directory, training_or_inference + \"_features.csv\")\n",
    "    y_path = os.path.join(saving_directory, training_or_inference + \"_response.csv\")\n",
    "    X.to_csv(X_path, index=False)\n",
    "    y.to_csv(y_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-02_15-41-55.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-02_15-41-55_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-02_16-09-16.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-02_16-09-16_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-07_15-58-43.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-07_15-58-43_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-07_17-00-10.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-07_17-00-10_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-08_13-16-56.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-08_13-16-56_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-08_15-11-29.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-08_15-11-29_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-09_11-14-43.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-09_11-14-43_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-09_12-07-02.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-09_12-07-02_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-14_14-23-48.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-14_14-23-48_EventProtocol.txt\n",
      "Loading file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-14_15-22-56.dat_labeled.json\n",
      "indices found for current file: 3\n",
      "Loading event file: c:\\Users\\liule\\Desktop\\semester project\\Analysis Model\\liuleyangsemesterproject\\training_data\\2023-03-14_15-22-56_EventProtocol.txt\n"
     ]
    }
   ],
   "source": [
    "data_pipeline_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SemesterProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
